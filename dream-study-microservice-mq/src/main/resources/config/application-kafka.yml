spring:
  kafka:
    # 集群地址
    bootstrap-servers:
    - 127.0.0.1:9092
    - 127.0.0.1:9093
    # 生产者配置
    producer:
      # 生产者缓冲区大小
      buffer-memory: 33554432
      # Kafka提供的序列化和反序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 重试次数
      retries: 0
      # 应答级别:多少个分区副本备份完成时向生产者发送ack确认,可选0,1,all/-1
      acks: 1
      # 批量大小
      batch-size: 16384
      properties:
        # 提交延时
        linger.ms: 0
        # 自定义分区器
        # partitioner.class=com.ssi.kafka.CustomizePartitiner
    # 消费者配置
    consumer: 
      # 批量消费每次最多消费多少条消息
      max-poll-records: 50
      # 是否自动提交offset
      enable-auto-commit: true
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset
      # latest:重置为分区中最新的offset(消费分区中新产生的数据)
      # none:只要有一个分区不存在已提交的offset,就抛出异常
      auto-offset-reset: latest
      # 提交offset延时(接收到消息后多久提交offset)
      auto-commit-interval:
        seconds: 1
      # Kafka提供的序列化和反序列化类
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties: 
        # 默认的消费组ID
        group.id: defaultConsumerGroup
        # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        session.timeout.ms: 120000
        # 消费请求超时时间
        request.timeout.ms: 180000
    listener: 
      # 消费端监听的topic不存在时,项目启动会报错(关掉)
      missing-topics-fatal: false
      # 设置批量消费
      type: batch
# Kafka

* Kafka由多个broker组成,每个broker是一个节点,可以认为是一台服务器
* 创建一个Topic,这个Topic可以划分为多个分区(Partition),每个Partition可以存在于不同的broker上,每个Partition就放一部分数据,数据是均匀地放在多个分区中的
* 每个分区中数据是严格按照顺序排列的,但多个分区中的顺序并不是严格的按照生产者放入消息的顺序排列
* 分区中的每条消息都会有一个唯一的offset做标识,只在当前分区中唯一
* 消费者可以以任意顺序消费分区中的消息,不需要按照消息在分区中的顺序进行消费.可以重复消费消息
* 消费者消费消息之后,并不会立刻从队列中删除,而是指定时间后删除,默认7天,可配置
* 这就是天然的分布式消息队列,一个Topic的数据,是分散放在多个机器上的,每个机器就放一部分数据
* Kafka提供了HA机制,就是replica副本机制
* 每个Partition的数据都会同步到其他机器上,形成自己的多个replica副本
* 然后所有replica会选举一个leader出来,那么生产和消费都跟这个leader打交道,然后其他replica就是follower
* 写数据的时候,leader会负责把数据同步到所有follower上去,读的时候就直接读leader上数据即可
* 写数据时,生产者就写leader,其他follower主动从leader来pull数据,一旦所有follower同步好数据了,就会发送ack给leader,leader收到所有follower的ack之后,就会返回写成功的消息给生产者
* Kafka会均匀的将一个Partition的所有replica分布在不同的机器上,这样才可以提高容错性
* 消费者组:Kafka会把一条消息路由到组中的某一个服务,这样有助于消息的负载均衡,也方便扩展消费者



# 模式



## 点对点

* 消费者主动从队列中拉取数据,消息收到后消息清除



## 发布/订阅

* 一条消息对应多个消费者,数据产生后,将推送给所有订阅的消费者



# 消息重复消费

* 比如A服务消费了MQ中的消息,A刚要回复MQ时挂了,而MQ没有等到A的回复,那MQ就认为该消息还没被消费
* 当A服务重启的时候,发现上次消费了的消息还在,继续消费,此时就发生了重复消费
* 解决的办法是没有的,只能减少,比如每次消费前从Redis中查询该消息是否被消费,没有就继续消费,有就跳过.但该方法只是换汤不换药,若是在A服务向Redis中写消息的时候挂了,一样会出现重复消费



# 消息丢失



## RabbitMQ

* 生产者使用confirm机制
* MQ对数据持久化
* 消费者需要手动进行ACK机制确认



## Kafka



# 顺序消费

* 将需要进行顺序消费的数据都放在一个queue中,而不是放在多个queue中,即放在单个partition中



# 数据积压

* 临时增加queue数量